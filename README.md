# Tyny - Real-Time Translation

Tyny is a real-time audio transcription and translation app. This project is both an exercise to gain deeper understanding of ASR and a proof of concept for a real-time transcription and translation system that could be used at live events.

In an effort to reduce compute resources and network latency, I wanted to test how well the ASR and translation models would run on the client. The current implementation uses a combination of Whisper and NLLB models running in the browser.

Although the current implementation can perform transcription and translation, it can't quite do so in real-time and can only translate one language at a time. The next step is to build out a backend system that can leverage more efficient ASR models and perform simultaneous translations for multiple languages.

## Features

- ğŸ™ï¸ Real-time audio transcription
- ğŸŒ Single language translation (English to all languages supported by NLLB-200)
- ğŸ’» Fully local

## Progress

- âœ… Build basic FE to display live translation/transcription
  - âœ… Configure VAD, ASR, and NLLB models to run in web workers
  - âœ… Let users choose audio input source (microphone or file)
  - âœ… Let users choose target language for translation
  - âœ… Indicate in the toolbar when speech is detected
  - âœ… Notify user when models are loading on startup
  - âœ… Alert user when WebGPU is not supported
- âœ… Backend system to handle transcription and translation
  - âœ… Add support for multiple translation languages
  - âœ… Add support for Nvidia's Parakeet models
  - âœ… Provide feedback to the user every second
  - âœ… Allow users to create translation "rooms" that can be joined by other users
- ğŸ“ Create a frontend system to handle the translation room

Legend:

- âœ… Completed
- ğŸš§ In Progress
- ğŸ“ Planned
